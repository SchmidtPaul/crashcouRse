---
title: "Mehr Details zur Vorgehensweise"
---

An dieser Stelle sollen einige Punkten der vorgestellten allgemeinen Vorgehensweisen etwas diskutiert werden. 

# Mittelwertvergleich nach ANOVA

In den Beispielen dieser Seite folgen wir immer der Standardprozedur: 

1. Das korrekte Modell (`lm()`, `gls()`, `glm()`, `lmer()` etc.) aufstellen
2. Eine ANOVA durchf√ºhren (`anova()`) und danach f√ºr die signifikanten Behandlungsfaktoren
3. Mittelwerte sch√§tzen und diese vergleichen  (`emmeans()`).

Schritt 3 wird als logischer n√§chster Schritt angesehen, da wir nach der ANOVA lediglich wissen, **dass** es signifikante Unterschiede zwischen Behandlungen gibt. Wir wissen dadurch aber noch nicht, **welche** Behandlungen sich unterscheiden. Ob Schritt 3 tats√§chlich nur auf Signifikanzen in Schritt 2 folgen darf, h√§ngt sowohl von den Daten/dem Modell/der Testmethode ab, als auch von den Ansichten des Statistikers, der die Analyse durchf√ºhrt. 

> Wenn der F-Test einer Behandlung in der ANOVA signifikant sein **muss**, bevor man einen t-test durchf√ºhren **darf**, spricht man auch vom
*protected LSD test*. Wenn man paarweise Mittelwerte auch unabh√§ngig vom Ergebnis des F-Tests mittels t-test Vergleich durchf√ºhren darf, spricht man
dementsprechend auch vom *Unprotected LSD test*.

# *Post hoc*: t-test, Tukey Test ...?

Es gibt mehrere Methoden um multiple Mittelwertvergleiche durchzuf√ºhren, z.B.:

* Multipler t-Test (Fisher ~1940?)
* Tukey-Test (John Tukey, 1949)
* Dunnett Test (Charles Dunnett, 1955)
* Scheff√© Test (Henry Scheff√©, 1959)
* Holm-Bonferroni Test (Sture Holm & Carlo Emilio Bonferroni, 1979)

Vorneweg soll gesagt sein, dass es keinen einzigen besten Test gibt, sondern, dass jeder der Tests verschiedene Vor- und Nachteile hat. Wir wollen erstmal nur zwei Methoden betrachten: Den multiplen t-Test und den Tukey-Test. Die Gegen√ºberstellung beider Methoden ist in folgender Tabelle zusammengefasst:

. | Multipler t-test | Tukey Test
--|------------------|-----------
Alternative Namen | Fishers LSD-Test | HSD-Test Tukey-Kramer Methode
Grenzdifferenz Name | **L**east **S**ignificant **D**ifference | **H**onestly **S**ignificant **D**ifference
GrenzdifferenzFormel | Kapitel 4.5.1 Statistikskript | Kapitel 4.5.3 Statistikskript
Fehler 1. Art ($\alpha$-Fehler) wird eingehalten f√ºr | den einzelnen Vergleich - "vergleichsbezogen" | Die Gesamtheit aller Vergleiche - "versuchsbezogen"
Korrigiert der Test daf√ºr, dass es mehrere Vergleiche gibt? | Nein | Ja

Beide Tests berechnen eine *Grenzdifferenz*, an der dann die Differenzen zwischen den Behandlungsstufen-Mittelwerten gemessen werden. Sind letztere gr√∂√üer als die Grenzdifferenz, gelten sie als *statistisch signifikant*. 

Was ist also der Unterschied zwischen mutliplem t-test und Tukey Test? Der Unterschied liegt in ihrer Umgangsweise mit dem *Fehler 1. Art*, auch $\alpha$ùõº-Fehler genannt (siehe dazu Kapitel 3.13 Statistikskript). Als kurze Zusammenfassung: Statistische Tests sind nie perfekt und es k√∂nnen Fehler passieren, sodass das Ergebnis des Tests eventuell nicht die Wahrheit abbildet. Es gibt zwei Arten von Fehlern, die passieren k√∂nnen: Die Nullhypothese ist eigentlich wahr, wird aber vom Test f√§lschlicherweise verworfen (Fehler 1. Art) oder die Nullhypothese ist eigentlich falsch, wird aber vom Test f√§lschlicherweise beibehalten (Fehler 2. Art) ‚Äì siehe dazu die Tabelle. 

<img src="images/alphabeta.jpg" style="width:80%" align="center"> 

Die Wahrscheinlichkeit, dass solche Fehler passieren (Irrtumswahrscheinlichkeit), kann man kontrollieren, aber ganz verhindern kann man es nicht. Die beiden Fehler bedingen sich auch noch gegenseitig, sodass der eine gr√∂√üer wird, wenn man den anderen klein halten m√∂chte. Dies ist einer der Gr√ºnde warum oft $\alpha$ = 0.05 gew√§hlt wird. Es bedeutet einfach, dass die Wahrscheinlichkeit, dass dem Test ein Fehler 1. Art unterl√§uft bei 5% liegt und dies scheint in den meisten F√§llen ein guter Kompromiss zu sein.

## Wie also gehen der multiple t-Test und der Tukey-Test mit dem Fehler 1. Art um?

Der multiple t-Test fixiert die Wahrscheinlichkeit f√ºr einen Fehler 1. Art (= ùõº) pro paarweisem Vergleich. Das hei√üt f√ºr jeden einzelnen Vergleich gilt, dass die Wahrscheinlichkeit einen $\alpha$ùõº-Fehler zu begehen nicht √ºber ùõº = 5% liegt. Andersherum hei√üt das, dass wir mit 95% Wahrscheinlichkeit
eine Nullhypothese korrekterweise beibehalten. W√ºrden wir also beispielsweise
genau 100 paarweise Vergleiche durchf√ºhren in denen in Wirklichkeit die Nullhypothese gilt, w√ºrden wir erwartungsgem√§√ü leider 5 mal ein falsches Testergebnis erhalten.

Man k√∂nnte sich auch fragen wie hoch die Wahrscheinlichkeit liegt, dass wir bei **allen** paarweisen Vergleichen die Nullhypothese korrekterweise
beibehalten. Bei den 100 Vergleichen w√§re das $(1-\alpha)^{100}=0.95^{100}=0,006=0,6%$. Demnach betr√§gt die Wahrscheinlichkeit bei den 100 Vergleichen mindestens einen $\alpha$ùõº-Fehler zu begehen in diesem Fall erschreckende 99,4%. Dieses Problem wird ‚ÄûMultiple comparison problem‚Äú oder auch ‚ÄûAlphafehler-Kumulierung‚Äú genannt. Sicherlich sind 100 Vergleiche eine extremes Beispiel, doch es muss klar sein, wie schnell die Anzahl der Vergleiche in Abh√§ngigkeit von der Anzahl der zu vergleichenden Behandglungsstufen steigt. Schon bei 4 Behandlungsstufen (z.B. 4 Sorten) gibt es 6 Vergleiche, sodass $(1-\alpha)^{6}=0.95^{6}=0,735=73,6%$. Also liegt selbst hier die Wahrscheinlichkeit mindestens einen $\alpha$-Fehler zu begehen schon bei 26,5%.

Im Gegensatz zum multiplen t-Test korrigiert der Tukey-Test daf√ºr, dass es mehrere Vergleiche gibt. Er fixiert die Wahrscheinlichkeit f√ºr einen Fehler 1. Art **pro Versuch - also √ºber alle paarweisen Vergleiche**. Die Grenzdifferenz wird schlichtweg so berechnet, dass die Wahrscheinlichkeit im ganzen Versuch mindestens einen $\alpha$ùõº-Fehler zu begehen eben nicht bei
99,4% oder 26,5% liegt, sondern den Wert von 5% nicht √ºberschreitet.

Aus diesem Grund ist die HSD stets gr√∂√üer als die LSD, sodass mit dem Tukey-Test weniger Behandlungsunterschiede als signifikant eingestuft werden als mit dem multiplen t-Test. Es wird quasi ‚Äûauf Nummer sicher gegangen um weniger Fehler zu begehen‚Äú. Man spricht deshalb davon, dass der Tukey-Test konservativer ist als der multiple t-Test.

## Fazit

Nachdem dies nun alles besprochen wurde, h√§tte man gerne eine klare, finale Faustregel zur Vorgehensweise. Wenn es allerdings eine g√§be, h√§tten wir uns diesen ganzen Exkurs auch sparen und nur den besseren der beiden Tests anschauen k√∂nnen. Stattdessen hier zum Abschluss das Zitat aus Kapitel 4.5.2 des Statistikskripts:

> ‚ÄûEs ist eine schwierige Frage, welche der beiden Irrtumswahrscheinlichkeiten eingehalten werden soll. Es gibt hierzu kaum eine einfache Regel. Aussagen, die unter Einhaltung der versuchsbezogenen Irrtumswahrscheinlichkeit getroffen werden, sind st√§rker abgesichert. Allerdings ist diese Absicherung nicht umsonst: Sie geht bei Tests zu Lasten eines gr√∂√üeren Fehlers 2. Art (Alternativhypothese f√§lschlicherweise verworfen). [‚Ä¶] Eine denkbare Strategie besteht darin, zu Beginn eines Projektes, wenn noch nach interessanten, weiter zu verfolgenden Zusammenh√§ngen gesucht wird, eher vergleichsbezogen zu testen, w√§hrend zu Projektende eine st√§rkere Absicherung durch versuchsbezogene Tests angestrebt wird.‚Äú




